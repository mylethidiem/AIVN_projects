{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mylethidiem/artificial-intelligence-projects/blob/main/Architecture%20Project%20Gradient%20Vanishing%20in%20MLP/7_GradientNorm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HItsinp0SFqA",
      "metadata": {
        "id": "HItsinp0SFqA"
      },
      "source": [
        "## **0. Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb96f0ec-3525-4e79-9ad1-8e95c15a9cf2",
      "metadata": {
        "id": "bb96f0ec-3525-4e79-9ad1-8e95c15a9cf2"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt # truc quan hoa\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from torchvision.datasets import FashionMNIST #download fashion mnist data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "P3ehfc2p0vqq",
      "metadata": {
        "id": "P3ehfc2p0vqq"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "def set_seed(seed):\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "\n",
        "SEED = 42\n",
        "set_seed(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Mw6hLiNAugrD",
      "metadata": {
        "id": "Mw6hLiNAugrD"
      },
      "source": [
        "## **1. Prepare dataset**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c73f1e96-b8ea-4b8f-b4f3-9b3f27b42acd",
      "metadata": {
        "id": "c73f1e96-b8ea-4b8f-b4f3-9b3f27b42acd"
      },
      "outputs": [],
      "source": [
        "train_dataset = FashionMNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "test_dataset = FashionMNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ratio = 0.9\n",
        "# train_size là số lượng mẫu dữ liệu dùng để train (54000 mẫu = 90% của tập train_dataset)\n",
        "train_size = int(train_ratio * len(train_dataset)) #90%\n",
        "val_size = len(train_dataset) - train_size #10%\n",
        "\n",
        "# train_subset là tập dữ liệu con được tạo ra bằng cách chia ngẫu nhiên train_dataset thành 2 phần\n",
        "# Hàm random_split() chia train_dataset thành 2 tập con:\n",
        "# - train_subset: chứa train_size mẫu (54000 mẫu)\n",
        "# - val_subset: chứa val_size mẫu (6000 mẫu)\n",
        "train_subset, val_subset = random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
        "# Tại sao lại shuffle tập data train?\n",
        "val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "print(f\"Train size: {len(train_subset)}\")\n",
        "print(f\"Validation size: {len(val_subset)}\")\n",
        "print(f\"Test size: {len(test_dataset)}\")"
      ],
      "metadata": {
        "id": "z7RaVrLgpMx3"
      },
      "id": "z7RaVrLgpMx3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "75eeaa46",
      "metadata": {
        "id": "75eeaa46"
      },
      "source": [
        "## **2. Build MLP network `with Gradient Norm`**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uthwgJntUNpq",
      "metadata": {
        "id": "uthwgJntUNpq"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self, input_dims, hidden_dims, output_dims):\n",
        "    super(MLP, self).__init__()\n",
        "    self.layer1 = nn.Linear(input_dims, hidden_dims)#\n",
        "    self.layer2 = nn.Linear(hidden_dims, hidden_dims)\n",
        "    self.layer3 = nn.Linear(hidden_dims, hidden_dims)\n",
        "    self.layer4 = nn.Linear(hidden_dims, hidden_dims)\n",
        "    self.layer5 = nn.Linear(hidden_dims, hidden_dims)\n",
        "    self.layer6 = nn.Linear(hidden_dims, hidden_dims)\n",
        "    self.layer7 = nn.Linear(hidden_dims, hidden_dims)\n",
        "    self.output = nn.Linear(hidden_dims, output_dims)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = nn.Flatten()(x)\n",
        "    x = self.layer1(x)\n",
        "    x = nn.Sigmoid()(x)\n",
        "    x = self.layer2(x)\n",
        "    x = nn.Sigmoid()(x)\n",
        "    x = self.layer3(x)\n",
        "    x = nn.Sigmoid()(x)\n",
        "    x = self.layer4(x)\n",
        "    x = nn.Sigmoid()(x)\n",
        "    x = self.layer5(x)\n",
        "    x = nn.Sigmoid()(x)\n",
        "    x = self.layer6(x)\n",
        "    x = nn.Sigmoid()(x)\n",
        "    x = self.layer7(x)\n",
        "    x = nn.Sigmoid()(x)\n",
        "    out = self.output(x)\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "589bb0df",
      "metadata": {
        "id": "589bb0df"
      },
      "outputs": [],
      "source": [
        "input_dims = 784 #28x28 pixel = 784 pixel\n",
        "#2^7:giá trị đủ lớn để có thể học đc các đặc trưng phức tạp, không quá lớn để bị overfitting\n",
        "hidden_dims = 128\n",
        "output_dims = 10 #10 class\n",
        "lr = 1e-2\n",
        "model = MLP(input_dims, hidden_dims, output_dims).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0db5beca-ee90-4d2e-bb2f-62b20da68cf3",
      "metadata": {
        "id": "0db5beca-ee90-4d2e-bb2f-62b20da68cf3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "lBS7q-JzwFgC",
      "metadata": {
        "id": "lBS7q-JzwFgC"
      },
      "source": [
        "## **3. Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21211483-aeed-4beb-aeea-d1e58ae7baf9",
      "metadata": {
        "id": "21211483-aeed-4beb-aeea-d1e58ae7baf9"
      },
      "outputs": [],
      "source": [
        "# Số lượng epochs (chu kỳ huấn luyện) cho quá trình training\n",
        "# Mỗi epoch, mô hình sẽ được huấn luyện trên toàn bộ tập dữ liệu training một lần\n",
        "# Với epochs = 100, mô hình sẽ được huấn luyện 100 lần trên tập dữ liệu\n",
        "epochs = 100\n",
        "train_loss_lst =[]\n",
        "train_acc_lst = []\n",
        "val_loss_lst = []\n",
        "val_acc_lst = []\n",
        "\n",
        "# Lặp qua số epochs đã định\n",
        "for epoch in range(epochs):\n",
        "  # Khởi tạo các biến để tính loss và accuracy cho tập train\n",
        "  train_loss = 0\n",
        "  train_acc = 0\n",
        "  count = 0\n",
        "  # Chuyển model sang chế độ train\n",
        "  model.train()\n",
        "  # Lặp qua từng batch dữ liệu train\n",
        "  for X_train, y_train in train_loader:\n",
        "    # Chuyển dữ liệu sang device (GPU/CPU)\n",
        "    X_train = X_train.to(device)\n",
        "    y_train = y_train.to(device)\n",
        "    # Xóa gradient tích lũy từ bước trước\n",
        "    optimizer.zero_grad()\n",
        "    # Forward pass: tính output của model\n",
        "    outputs = model(X_train)\n",
        "    # Tính loss giữa output và ground truth\n",
        "    loss = criterion(outputs, y_train)\n",
        "    # Backward pass: tính gradient\n",
        "    loss.backward()\n",
        "    # Cập nhật trọng số dựa trên gradient\n",
        "    optimizer.step()\n",
        "    # Cộng dồn loss và accuracy\n",
        "    train_loss += loss.item()\n",
        "    # Tính số lượng dự đoán đúng trong batch hiện tại:\n",
        "    # 1. torch.argmax(outputs,1): Lấy chỉ số của giá trị lớn nhất trên mỗi hàng (dim=1) của outputs\n",
        "    #    -> Đây chính là nhãn được dự đoán bởi mô hình\n",
        "    # 2. == y_train: So sánh với nhãn thực tế, trả về tensor boolean (True nếu dự đoán đúng)\n",
        "    # 3. .sum(): Đếm số lượng giá trị True (số lượng dự đoán đúng)\n",
        "    # 4. .item(): Chuyển đổi tensor thành số Python\n",
        "    # Cộng dồn số lượng dự đoán đúng vào biến train_acc\n",
        "    train_acc += (torch.argmax(outputs,1) == y_train).sum().item()\n",
        "    count += len(y_train)\n",
        "  # Tính trung bình loss và accuracy trên tập train\n",
        "  train_loss /= len(train_loader)\n",
        "  train_loss_lst.append(train_loss)\n",
        "  train_acc /= count\n",
        "  train_acc_lst.append(train_acc)\n",
        "\n",
        "  # Khởi tạo các biến để tính loss và accuracy cho tập validation\n",
        "  val_loss = 0.0\n",
        "  val_acc = 0.0\n",
        "  count = 0\n",
        "  # Chuyển model sang chế độ evaluation\n",
        "  model.eval()\n",
        "  # Tắt tính toán gradient khi validate vì:\n",
        "  # 1. Không cần cập nhật trọng số trong quá trình validation\n",
        "  # 2. Giúp tăng tốc độ tính toán và tiết kiệm bộ nhớ\n",
        "  # 3. Đảm bảo kết quả đánh giá nhất quán vì không có sự thay đổi của trọng số\n",
        "  with torch.no_grad():\n",
        "    # Lặp qua từng batch dữ liệu validation\n",
        "    for X_val, y_val in val_loader:\n",
        "      # Chuyển dữ liệu sang device\n",
        "      X_val = X_val.to(device)\n",
        "      y_val = y_val.to(device)\n",
        "      # Tính output\n",
        "      outputs = model(X_val)\n",
        "      # Tính loss\n",
        "      loss = criterion(outputs, y_val)\n",
        "      # Cộng dồn loss và accuracy\n",
        "      val_loss += loss.item()\n",
        "      val_acc += (torch.argmax(outputs,1) == y_val).sum().item()\n",
        "       # Train size có thể khác so với tổng số mẫu thực tế dùng(do loại bỏ mẫu lỗi..?)\n",
        "      count += len(y_val)\n",
        "  # Tính trung bình loss và accuracy trên tập validation\n",
        "  val_loss /= len(val_loader)\n",
        "  val_loss_lst.append(val_loss)\n",
        "  val_acc /= count # Chia cho số mẫu thực tế đã sử dụng\n",
        "  val_acc_lst.append(val_acc)\n",
        "\n",
        "  # In kết quả sau mỗi epoch\n",
        "  print(f\"EPOCH {epoch+1}/{epochs}, Train_Loss: {train_loss:.4f},Train_Acc: {train_acc:.4f}, Validation Loss: {val_loss:.4f} , Val_Acc:{val_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "321d7070-b736-4ebb-94fa-59cd37ff50b3",
      "metadata": {
        "id": "321d7070-b736-4ebb-94fa-59cd37ff50b3"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(2, 2, figsize=(12, 10))\n",
        "ax[0, 0].plot(train_loss_lst, color='green')\n",
        "ax[0, 0].set(xlabel='Epoch', ylabel='Loss')\n",
        "ax[0, 0].set_title('Training Loss')\n",
        "\n",
        "ax[0, 1].plot(val_loss_lst, color='orange')\n",
        "ax[0, 1].set(xlabel='Epoch', ylabel='Loss')\n",
        "ax[0, 1].set_title('Validation Loss')\n",
        "\n",
        "ax[1, 0].plot(train_acc_lst, color='green')\n",
        "ax[1, 0].set(xlabel='Epoch', ylabel='Accuracy')\n",
        "ax[1, 0].set_title('Training Accuracy')\n",
        "\n",
        "ax[1, 1].plot(val_acc_lst, color='orange')\n",
        "ax[1, 1].set(xlabel='Epoch', ylabel='Accuracy')\n",
        "ax[1, 1].set_title('Validation Accuracy')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CY9OpDyiPL2V",
      "metadata": {
        "id": "CY9OpDyiPL2V"
      },
      "source": [
        "## **4. Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VC8cygPWPKy6",
      "metadata": {
        "id": "VC8cygPWPKy6"
      },
      "outputs": [],
      "source": [
        "# Khởi tạo list rỗng để lưu trữ nhãn thực tế của tập test\n",
        "# Sau đó sẽ được sử dụng để so sánh với dự đoán của mô hình\n",
        "test_target = []\n",
        "test_predict = []\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  for X_test, y_test in test_loader:\n",
        "    X_test = X_test.to(device)\n",
        "    y_test = y_test.to(device)\n",
        "    outputs = model(X_test)\n",
        "\n",
        "    test_target.append(y_test.cpu())# ko cần tính toán trên GPU nữa\n",
        "    test_predict.append(outputs.cpu())\n",
        "\n",
        "# Ghép các batch của nhãn thực tế và dự đoán thành một tensor duy nhất\n",
        "# Shape: (batch_size, channels, height, width)\n",
        "# dim=0: ghép theo batch\n",
        "# dim=1: ghép theo kênh màu\n",
        "# dim=2: ghép theo chiều cao\n",
        "# dim=3: ghép theo chiều rộng\n",
        "\n",
        "# Tensor 2D thông thường:\n",
        "#dim=0  # Ghép theo hàng (vertically)\n",
        "#dim=1  # Ghép theo cột (horizontally)\n",
        "\n",
        "# Tensor nhiều chiều:\n",
        "#dim=n  # n là chỉ số của chiều muốn ghép (0-based indexing)\n",
        "test_target = torch.cat(test_target, dim=0) #ghép theo chiều thứ nhất chiều batch(chiều dọc)\n",
        "test_predict = torch.cat(test_predict, dim=0)\n",
        "\n",
        "# Tính độ chính xác trên tập test:\n",
        "# 1. torch.argmax(test_predict,1) - Lấy chỉ số của giá trị lớn nhất trên mỗi hàng (dự đoán của mô hình)\n",
        "# 2. So sánh với nhãn thực tế (test_target)\n",
        "# 3. Tính tổng số dự đoán đúng và chia cho tổng số mẫu\n",
        "test_acc = (torch.argmax(test_predict,1)==test_target).sum().item()/len(test_target)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vsTDEJ92P6Pa",
      "metadata": {
        "id": "vsTDEJ92P6Pa"
      },
      "outputs": [],
      "source": [
        "val_label = []\n",
        "val_predict = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  for X_val, y_val in val_loader:\n",
        "    X_val, y_val = X_val.to(device), y_val.to(device)\n",
        "\n",
        "    output = model(X_val)\n",
        "\n",
        "    # transfer to CP, currently it is tensor\n",
        "    val_label.append(y_val.cpu())\n",
        "    val_predict.append(output.cpu())\n",
        "\n",
        "  val_label = torch.cat(val_label, dim=0)\n",
        "  val_predict = torch.cat(val_predict, dim=0)\n",
        "  val_acc = (torch.argmax(val_predict, dim=1) == val_label).sum().item()/len(val_label)\n",
        "\n",
        "print(f\"Validation accuracy: {val_acc:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}